
# 机器人

https://github.com/huggingface/lerobot

## ICRT

[code](https://github.com/Max-Fu/icrt/tree/main) | [model](https://huggingface.co/mlfu7/ICRT) | [Datasets](https://huggingface.co/datasets/Ravenh97/ICRT-MT)

### Install
按照教程基本就装好了
```shell
# create conda env
conda create -n icrt python=3.10 -y
conda activate icrt
# install torch 参考【Log】-【Linux环境】-【PyTorch】

conda install -c conda-forge ffmpeg
# download repo
git clone https://github.com/Max-Fu/icrt.git
cd icrt
pip install -e .
```

安装Jupyter Notebook: 参考【Log】-【Linux环境】-【Python常见库安装】-【Jupyter Notebook】


### Quick Start

#### 模型下载
先只下载`crossmae_rtx`和`icrt_vitb_droid_pretrained`两个文件夹中的文件即可。然后在运行过程中还可能会有其他模型会自动从Hugging Face上拉取

#### 数据集准备
下载任意一个hdf5文件即可，每一个hdf5文件中都有一个对应的`keys.json`文件，可以用来查看文件中都有哪些序列。

#### 开始推演
准备好模型和数据集后就可以直接使用，使用写好的Jupyter Notebook，文件是`tools/inference.ipynb`，基本上最大的问题是中途用了一个未知的模型要从HuggingFace下载

如果想启用数据集可视化代码可能会遇到动画最大容量限制的警告，按照警告的内容把允许容量设大一些
```python
plt.rcParams['animation.embed_limit'] = 300
```

### 参数配置
打开`run.yaml`文件可以看到配置，其中包含有llama2的路径。

在`Breadcrumbsicrt/icrt/models/policy/icrt.py`中有：
```python
        if self.scratch_llama_config is not None:
            llama_config_path = self.scratch_llama_config
        else:
            llama_config_path = os.path.join(llama_ckpt_dir, "params.json")
```

可以看到，当`scratch_llama_config`有值时，是直接走的对应的配置文件，这个配置文件在路径`config/model_config`下：


::: code-group
```json [工程中的custom_transformer.json]
{
  "dim": 768,
  "multiple_of": 256,
  "n_heads": 12,
  "n_layers": 12,
  "norm_eps": 1e-05,
  "vocab_size": -1
}
```

```json [Llama2的params.json]
{
  "dim": 4096,
  "multiple_of": 256,
  "n_heads": 32,
  "n_layers": 32,
  "norm_eps": 1e-05,
  "vocab_size": -1
}
```
:::

