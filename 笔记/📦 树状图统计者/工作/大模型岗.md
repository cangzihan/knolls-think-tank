# 大模型岗

## 基础面
1. 目前主流的开源模型体系有哪些

::: details 答案
- GPT-4o:
  1. GPT (Generative Pre-trained Transformer) 系列：

  GPT-2 和 GPT-3：由OpenAI发布，广泛用于自然语言生成和理解任务。GPT-3有1750亿参数，是目前最大的预训练语言模型之一。 GPT-Neo 和 GPT-J：由EleutherAI发布，旨在提供开源的替代方案，性能接近GPT-3。

  2. BERT (Bidirectional Encoder Representations from Transformers) 系列：
  - BERT：由Google发布，专注于句子级别的理解任务。BERT的双向训练使其在多个NLP任务上表现出色。
  - RoBERTa：Facebook AI对BERT进行优化和改进，提升了性能。
  - DistilBERT：由Hugging Face发布，是BERT的轻量版本，具有更小的尺寸和更快的推理速度。
  3. T5 (Text-To-Text Transfer Transformer)：
  由Google Research发布，将所有文本任务转化为文本生成任务，实现了统一处理的框架。T5在多种NLP任务上表现优异。
  4. Transformers by Hugging Face：
Hugging Face提供了丰富的预训练模型和工具库，包括BERT、GPT、T5等，成为NLP开发者的常用资源。

  6. XLNet：
由Google Brain和CMU合作发布，结合了自回归和自编码模型的优势，提升了在多个基准上的表现。

  7. ERNIE (Enhanced Representation through kNowledge Integration)：
  由百度发布，整合了大规模知识图谱信息，增强了语义理解能力。

  8. CLIP (Contrastive Language-Image Pre-Training)：
由OpenAI发布，将文本和图像联合训练，用于多模态任务，展示了图文匹配的强大能力。

  9. DALL-E：
也是由OpenAI发布，能够根据文本描述生成图像，展示了跨模态生成的潜力。

  10. Vision Transformers (ViT)：
由Google Research提出，将Transformer应用于计算机视觉任务，打破了卷积神经网络（CNN）的传统优势。

:::

2. prefix LM和causal LM区别是什么？

::: details 答案
- GPT-4o:
  在自然语言处理领域，prefix LM（前缀语言模型）和causal LM（因果语言模型）是两种不同的语言模型架构，它们在训练和推理过程中的目标和方法有所不同。

  - Causal LM（因果语言模型）

  因果语言模型主要是以自回归方式进行训练和推理，即在生成每个词时仅依赖于该词之前的所有词。这种模型通过逐步预测下一个词来生成文本。

  - 训练过程：模型在训练时根据给定的序列前缀来预测下一个词。例如，对于输入序列 "The quick brown fox"，模型会依次训练预测 "quick"、"brown"、"fox"、以及序列末尾的词。
  - 推理过程：在推理时，模型从一个初始词开始逐步生成后续的词，每次生成一个词并将其添加到序列中，再使用更新后的序列预测下一个词。

  这种模型的典型代表是GPT（Generative Pre-trained Transformer）系列。

  - Prefix LM（前缀语言模型）

  前缀语言模型通常用于处理自然语言理解任务，它们接受一个前缀并生成对应的补全。与因果语言模型不同的是，前缀语言模型可以在一定程度上利用双向信息。

    - 训练过程：模型在训练时接受一个固定长度的前缀，并预测剩余部分。例如，对于一个输入序列 "The quick brown fox jumps over the lazy"，前缀 "The quick brown fox" 被用来预测 "jumps over the lazy"。
    - 推理过程：在推理时，模型接受一个前缀，生成该前缀之后的词序列。

  前缀语言模型在一定程度上类似于BERT的训练方式，但BERT是完全双向的，而前缀语言模型则是单向的，强调利用前缀信息生成后续内容。

  - 主要区别
    1. 信息使用方式：
    - Causal LM：仅使用前面的词来预测下一个词，自回归生成。
    - Prefix LM：利用前缀信息生成后续内容，但可以在一定程度上利用后面的词进行预测。
    2. 应用场景：
    - Causal LM：多用于文本生成和续写任务。
    - Prefix LM：多用于补全任务，例如对话生成、填空等。
    3. 模型结构和训练目标：
    - Causal LM：训练目标是最大化前序词给定条件下的下一个词的概率。
    - Prefix LM：训练目标是给定前缀预测后续内容，可以在序列的任意位置进行预测，但通常关注前缀后的内容生成。

:::

3. 涌现能力是啥原因？

::: details 答案
- GPT-4o:

  涌现能力（Emergent Abilities）是指在大型语言模型（LLMs）中，当模型参数或训练数据量达到某个临界规模时，模型会突然表现出一些在小规模模型中没有显现的新能力。这些能力可能包括更复杂的语言理解、推理、翻译、生成等任务。

  - 举例说明

  以GPT-3为例，早期的较小模型可能只能完成简单的补全任务，但当模型参数增加到百亿级别时，GPT-3展示出复杂的语言理解和生成能力，比如较高质量的翻译、复杂的对话生成以及在各种零样本学习任务中的表现。
:::

4. 大模型LLM的架构介绍？
::: details 答案
- GPT-4o:

  大型语言模型（Large Language Models, LLMs）的架构通常基于Transformer模型，这是一种用于处理序列数据的深度学习模型。

  - 特定模型架构
  1. GPT（Generative Pre-trained Transformer）
     - 只使用解码器部分的堆叠。
     - 自回归生成：模型在生成下一个词时仅依赖于之前生成的词。
     - GPT-3 是其中的代表，拥有1750亿参数，展示了强大的语言生成能力。

  2. BERT（Bidirectional Encoder Representations from Transformers）
     - 只使用编码器部分的堆叠。
     - 双向训练：同时考虑左侧和右侧上下文，擅长语言理解任务。
     - BERT的变体包括RoBERTa、DistilBERT等，都是在BERT基础上的优化。

  3. T5（Text-To-Text Transfer Transformer）
     - 使用编码器-解码器结构。
     - 统一处理框架：将所有任务（如翻译、摘要、问答）转化为文本生成任务。
:::

## 进阶面
1. llama输入句子长度理论上可以无限长吗？
::: details 答案
- GPT-4o:
  理论上，输入句子的长度可以非常长，但在实际应用中，受限于计算资源和架构设计，输入句子的长度是有限的。以LLM（大型语言模型）为例，特别是像LLaMA（Large Language Model Meta AI）这样的模型，其输入长度受以下几个因素的限制：

  1. 模型架构设计
Transformer模型，特别是自注意力机制，对输入序列的长度非常敏感。自注意力机制的计算复杂度是O(n^2)，其中n是输入序列的长度。因此，随着输入长度的增加，计算量和内存需求都将显著增加。

  2. 硬件限制
  现代计算硬件，如GPU和TPU，有有限的内存和计算能力。即使是高端的计算硬件，也无法处理超长的输入序列。例如，处理数千个甚至更多的词汇时，需要大量的显存（VRAM）和计算资源。

  3. 预训练和微调阶段的限制
  在模型的预训练和微调阶段，使用的输入序列长度通常会受到限制。这样做的目的是为了在有限的计算资源下进行有效的训练。常见的输入序列长度是512、1024或2048个词汇。

  4. 实际应用中的限制
  在实际应用中，模型的输入长度也会受到一些现实因素的影响，如响应时间、内存使用效率和硬件成本等。因此，即使理论上可以处理更长的序列，实际应用中通常会限制在一个可管理的长度内。

  - 具体例子：LLaMA模型
LLaMA模型是由Meta AI开发的大型语言模型，基于Transformer架构。与其他LLM一样，LLaMA的输入长度也受到上述限制。

    - 典型输入长度：大多数LLaMA模型在训练和使用时，输入长度通常限制在2048个词汇以内。
    - 特殊优化：为了处理较长的序列，研究人员可能会使用分块处理、滑动窗口或分段处理等技术，这些技术能够在一定程度上缓解输入长度的限制，但也会带来其他复杂性和额外的计算开销。

  - 应对长输入序列的策略

  为了处理长输入序列，有几种常见的方法：
  1. 分段处理：将长文本分割成多个较短的段落或片段，每个段落独立处理，然后将结果合并。这种方法在某些任务中效果较好，但会丢失跨段落的上下文信息。
  2. 滑动窗口：使用一个滑动窗口在长文本上移动，每次处理窗口内的子序列。窗口之间可以有重叠，以保持跨窗口的上下文信息。
  3. 层次化模型：使用一个分层模型结构，首先处理较短的片段，然后在更高层次上整合这些片段的信息。
  4. 长序列优化技术：研究和开发新的注意力机制或模型架构，如线性注意力、稀疏注意力或分块注意力，以减少长序列的计算复杂度和内存需求。
:::

## 评测面
1. 大模型怎么评测？
::: details 答案
- GPT-4o:
  1. 语言建模评测
语言模型的核心任务是预测序列中的下一个词，因此常用的评测方法包括：
     - 困惑度（Perplexity）：衡量模型在测试集上的预测准确性，数值越低表示模型越好。
     - 交叉熵（Cross-Entropy Loss）：衡量模型预测分布与真实分布之间的差异。
  2. 基准任务评测
  通过一系列标准的自然语言处理任务来评估模型的性能，如：
     - 问答任务（Question Answering）：例如SQuAD、NaturalQuestions。
     - 文本分类（Text Classification）：例如Sentiment Analysis、Topic Classification。
     - 文本生成（Text Generation）：例如故事生成、对话生成。
     - 机器翻译（Machine Translation）：例如WMT。
     - 文本摘要（Text Summarization）：例如CNN/Daily Mail。
  3. 综合评测基准
  使用多任务综合评测基准，测试模型在多个任务上的表现，例如：
     - GLUE（General Language Understanding Evaluation）：一套广泛使用的自然语言理解基准，包括句子相似度、自然语言推理、情感分析等任务。
     - SuperGLUE：GLUE的扩展版，包含更多复杂的任务。
     - XTREME：跨语言的评测基准，测试模型在不同语言上的表现。
  4. 生成质量评测
  对于生成任务，评测模型生成文本的质量是关键，常用的方法包括：
     - BLEU（Bilingual Evaluation Understudy）：主要用于机器翻译，衡量生成文本与参考文本的重合度。
     - ROUGE（Recall-Oriented Understudy for Gisting Evaluation）：主要用于文本摘要，评测生成文本与参考文本的n-gram重合情况。
     - METEOR：考虑词形变化和同义词的生成质量评测指标。
     - 人类评价：通过人工评估生成文本的流畅性、相关性和信息性。
  5. 效率评测
  评测模型在不同硬件和环境下的效率，包括：
     - 推理速度：每秒生成的词数或每秒处理的输入序列数。
     - 训练时间：完成训练所需的总时间。
     - 计算资源使用：所需的GPU/TPU内存和计算能力。
  6. 鲁棒性和公平性评测
  评估模型的鲁棒性和公平性，确保模型在各种输入情况下的稳定性和公正性，包括：
     - 对抗攻击：评估模型在对抗样本下的表现。
     - 噪声处理：评估模型对输入噪声的鲁棒性。
     - 公平性评估：检测模型是否存在偏见或歧视性行为。
  7. 可解释性和透明性
  了解和解释模型的行为和决策过程，包括：
     - 注意力机制可视化：查看模型在输入序列上的注意力分布。
     - 输入特征重要性：评估哪些输入特征对模型决策影响最大。
  8. 用户体验评测
  在实际应用中，评估用户对模型的体验，包括：
     - 用户满意度：通过问卷调查或用户反馈评估模型的使用体验。
     - 任务完成率：衡量用户使用模型完成特定任务的成功率。

  - 实例：GPT-3的评测
  OpenAI对GPT-3进行了多方面的评测，包括：
    - 语言建模困惑度：在标准测试集上的困惑度。
    - 多任务表现：在GLUE、SuperGLUE等基准上的表现。
    - 生成质量：通过BLEU、ROUGE等指标评测生成文本的质量。
    - 推理速度和资源使用：在不同硬件上的推理效率。
    - 鲁棒性测试：在对抗样本和噪声数据上的表现。
    - 用户体验调查：通过实际应用测试用户对模型生成内容的满意度。
:::

## langchain面
1. 什么是LangChain
::: details 答案
LangChain 是一个用于开发由语言模型驱动的应用程序的框架。它使得应用程序能够：

具有上下文感知能力：将语言模型连接到上下文来源（提示指令，少量的示例，需要回应的内容等）
具有推理能力：依赖语言模型进行推理（根据提供的上下文如何回答，采取什么行动等）

:::

2. 什么是LangChain Agent
::: details 答案
agent的核心思想是使用LLM来选择要采取的一系列动作。 在链式结构中，一系列动作是硬编码的（在代码中）。 在agent中，使用语言模型作为推理引擎来确定要采取的动作及其顺序。
:::

3. 基于LLM+向量库的文档对话，思路是怎么样？
::: details 答案
- GPT-4o:
  这种系统的核心目标是利用LLM的自然语言理解能力和向量库的高效检索能力，实现用户与文档的智能对话。基本流程包括文本预处理、向量化、检索、LLM回答生成等步骤。
:::

4. 基于LLM+向量库的文档对话，思路是怎么样？
::: details 答案
- GPT-4o:
  - 系统组件
    1. 文档预处理
    将文档进行分割和清洗，确保每个文档片段具有合理的长度和内容完整性。预处理步骤可能包括：
       - 文本清洗（去除HTML标签、标点符号等）
       - 分段（按段落、句子等分割文档）
    2. 向量化
    将预处理后的文档片段转换为向量表示。这通常通过预训练的语言模型（如BERT、RoBERTa等）来完成。
       - 嵌入模型：使用预训练的嵌入模型将文档片段转化为固定长度的向量表示。
       - 向量存储：将生成的向量存储在向量库中，以便高效检索。
    3. 向量库
       使用向量数据库（如FAISS、Annoy、Milvus等）存储和检索文档片段的向量表示。向量库支持高效的相似度搜索。
       - 索引构建：为存储的向量构建索引以提高检索效率。
       - 相似度搜索：根据用户查询向量进行相似度计算，检索出最相关的文档片段。
    4. 查询处理
    接受用户输入的查询，并将查询转换为向量表示，以便在向量库中进行检索。
       - 查询嵌入：使用与文档向量化相同的嵌入模型，将用户查询转换为向量。
       - 检索：在向量库中搜索与查询向量最相似的文档片段。
    5. 回答生成
    使用LLM生成基于检索到的文档片段的自然语言回答。回答生成步骤通常包括：
       - 上下文构建：将用户查询与检索到的相关文档片段构建成输入上下文。
       - 回答生成：使用LLM生成回答。模型根据上下文信息生成自然语言回答。
  - 技术细节
    1. 预训练模型选择
    选择合适的预训练模型进行向量化和生成。常用的模型包括：
       - BERT：适用于生成句子和段落的向量表示。
       - GPT-3：适用于自然语言生成，生成高质量的回答。
    2. 向量库选择
       选择高效的向量数据库进行向量存储和检索。常见的向量库包括：
       - FAISS：Facebook AI Research开发的高效相似性搜索库。
       - Annoy：Spotify开发的用于大规模高维向量相似性搜索的库。
       - Milvus：开源的向量数据库，支持大规模向量检索。
    3. 优化和调整
       - 向量化模型微调：对预训练模型进行微调，以提高向量表示的精度。
       - 检索精度优化：调整向量库的索引参数，以平衡检索精度和效率。
       - 回答生成优化：微调LLM，提高回答的相关性和准确性。
:::

5. 基于LLM+向量库的文档对话prompt模板如何创建？
::: details 答案
- GPT-4o:
  1. 问答模板
这种模板直接将用户查询和相关文档片段结合，引导模型生成直接回答。
  ```text
  Q: {用户查询}
  A: 根据以下信息生成答案：
  {检索到的文档片段1}
  {检索到的文档片段2}
  ...
  ```
  2. 摘要模板
  用于生成摘要型回答，将多个文档片段结合，生成一个综合性的答案。
  ```text
  Q: {用户查询}
  以下是一些相关的信息：
  1. {检索到的文档片段1}
  2. {检索到的文档片段2}
  3. {检索到的文档片段3}
  请基于以上信息生成一个综合的答案。
  A:
  ```
  3. 对话模板
  模拟对话的方式，引导模型生成更加自然和连贯的回答。
  ```text
  用户：{用户查询}
  系统：以下是一些相关的信息：
  1. {检索到的文档片段1}
  2. {检索到的文档片段2}
  3. {检索到的文档片段3}
  系统：请基于以上信息回答用户的问题。
  ```

:::


::: details 答案
- GPT-4o:
  答案模板
:::



::: tip

我不想搞这个岗位

:::
